{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/turksoyomer/hvac-occupancy-detection-with-ml-and-dl-methods?scriptVersionId=89546217\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# 1. Introduction\nFor this kernel, I'm using a dataset for predicting room occupancy with using environmental observations such as temperature, humidity and CO2 level. This predictions might help Heating, Ventilating and Air Conditioning (HVAC) sector. For instance, we are using sensors like thermostats to get information about the environment and with that info our system decides to heat or not situation. But if the thermostat set manually by a occupant before and there is no more occupants in the environment, what then? The system won't shutdown until it gets set values, and this situation will lead high energy consumption. \n\nLet's start with exploratory data analysis on data.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n# Importing necessary libraries for this notebook.\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt\nfrom plotly.offline import init_notebook_mode, iplot, plot\ninit_notebook_mode(connected=True)\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.regularizers import l2, l1\nfrom keras.metrics import BinaryAccuracy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datatest = pd.read_csv(\"/kaggle/input/occupancy-detection-data-set-uci/datatest.txt\")\ndatatest2 = pd.read_csv(\"/kaggle/input/occupancy-detection-data-set-uci/datatest2.txt\")\ndatatraining = pd.read_csv(\"/kaggle/input/occupancy-detection-data-set-uci/datatraining.txt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis\nWe have three different .txt file as datatest, datatest2 and datatraining.","metadata":{}},{"cell_type":"code","source":"print(datatest.info())\ndatatest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datatest2.info())\ndatatest2.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(datatraining.info())\ndatatraining.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All text files has seven columns as date, temperature, humidity, light, CO2, humidity ratio and occupancy. \n* Temperature in Celsius.\n* Relative humidity as a percentage.\n* Light measured in lux.\n* Carbon dioxide measured in parts per million.\n* Humidity ratio, derived from temperature and relative humidity measured in kilograms of water vapor per kilogram of air.\n* Occupancy as either 1 for occupied or 0 for not occupied.\n\nFor training and testing the models, I will use I will use datatraining(8143 instances) as training, datatest(2665 instances) as validation and datatest2(9752 instances) as test data.","metadata":{}},{"cell_type":"code","source":"datatest['date'] = pd.to_datetime(datatest['date'])\ndatatest2['date'] = pd.to_datetime(datatest2['date'])\ndatatraining['date'] = pd.to_datetime(datatraining['date'])\ndatatest.reset_index(drop=True, inplace=True)\ndatatest2.reset_index(drop=True, inplace=True)\ndatatraining.reset_index(drop=True, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datatraining.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we have low values like humidity_ratio and high values like light and CO2, we should normalize the data to simplfy the learning process.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\ncolumns = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']\nscaler.fit(np.array(datatraining[columns]))\ndatatest[columns] = scaler.transform(np.array(datatest[columns]))\ndatatest2[columns] = scaler.transform(np.array(datatest2[columns]))\ndatatraining[columns] = scaler.transform(np.array(datatraining[columns]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nplt.title('Box Plot for Features', fontdict={'fontsize':18})\nax = sns.boxplot(data=datatraining.drop(['date', 'Occupancy'],axis=1), orient=\"h\", palette=\"Set2\")\nprint(datatraining.drop(['date', 'Occupancy'],axis=1).describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.title('Correlation Table for Features', fontdict={'fontsize':18})\nax = sns.heatmap(datatraining.corr(), annot=True, linewidths=.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the correlations between occupancy and the others. As I expected, light value is more correlated with occupancy than others.","metadata":{}},{"cell_type":"code","source":"data = datatraining.copy()\ndata.Occupancy = data.Occupancy.astype(str)\nfig = px.scatter_3d(data, x='Temperature', y='Humidity', z='CO2', size='Light', color='Occupancy', color_discrete_map={'1':'red', '0':'blue'})\nfig.update_layout(scene_zaxis_type=\"log\", title={'text': \"Features and Occupancy\",\n                                                'y':0.9,\n                                                'x':0.5,\n                                                'xanchor': 'center',\n                                                'yanchor': 'top'})\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look on the 4-dimensional plot for occupancy. The 4th dimension is size of dots here and I used light value as 4th dimension. The higher light will lead to bigger dots and the lower light will lead to smaller dots. You can use your mouse to change your perspective and take a closer look on the graph.","metadata":{}},{"cell_type":"code","source":"sns.set(style=\"darkgrid\")\nplt.title(\"Occupancy Distribution\", fontdict={'fontsize':18})\nax = sns.countplot(x=\"Occupancy\", data=datatraining)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our data is unbalanced, so we need to find another relations between features to strengthen our predictions. I have a question at this point, is there any relation between occupancy and the hour of the day? Let's look into it.","metadata":{}},{"cell_type":"code","source":"hours_1 = []\nhours_0 = []\nfor date in datatraining[datatraining['Occupancy'] == 1]['date']:\n    hours_1.append(date.hour)\nfor date in datatraining[datatraining['Occupancy'] == 0]['date']:\n    hours_0.append(date.hour)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nax = sns.distplot(hours_1)\nax = sns.distplot(hours_0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From above histogram, what can you say? Between 07:00 and 18:00 there are occupants in the environment or not. But the time come to non-working hours, then we can absolutely say that there is no occupant. With this information, I will create a new feature from date column as day period.\n* 07:00 - 18:00 working hour (labeled as 1)\n* rest of the day non-working hour (labeled as 0)","metadata":{}},{"cell_type":"code","source":"datatest['period_of_day'] = [1 if (i.hour >= 7 and i.hour <= 17) else 0 for i in datatest['date']]\ndatatest2['period_of_day'] = [1 if (i.hour >= 7 and i.hour <= 17) else 0 for i in datatest2['date']]\ndatatraining['period_of_day'] = [1 if (i.hour >= 7 and i.hour <= 17) else 0 for i in datatraining['date']]\ndatatraining.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Classification with Machine Learning Methods","metadata":{}},{"cell_type":"code","source":"X_train = datatraining.drop(columns=['date', 'Occupancy'], axis=1)\ny_train = datatraining['Occupancy']\nX_validation = datatest.drop(columns=['date', 'Occupancy'], axis=1)\ny_validation = datatest['Occupancy']\nX_test = datatest2.drop(columns=['date', 'Occupancy'], axis=1)\ny_test = datatest2['Occupancy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1. KNN (K-Nearest Neighbors)\nLet's try different hyperparameters on KNN model such as n_neighbors, weights and metrics to find best options.","metadata":{}},{"cell_type":"code","source":"# parameter-tuning for knn\nn_neighbors_list = [7,15,45,135]\nweights_list = ['uniform', 'distance']\nmetric_list = ['euclidean', 'manhattan']\naccuracies = {}\nfor n in n_neighbors_list:\n    for weight in weights_list:\n        for metric in metric_list:\n            knn_model = KNeighborsClassifier(n_neighbors=n, weights=weight, metric=metric)\n            knn_model.fit(X_train, y_train)\n            accuracy = knn_model.score(X_validation, y_validation)\n            accuracies[str(n)+\"/\"+weight+\"/\"+metric] = accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotdata = pd.DataFrame()\nplotdata['Parameters'] = accuracies.keys()\nplotdata['Accuracy'] = accuracies.values()\nfig = px.line(plotdata, x=\"Parameters\", y=\"Accuracy\")\nfig.update_layout(title={'text': \"Accuracies for Different Hyper-Parameters\",\n                                                'x':0.5,\n                                                'xanchor': 'center',\n                                                'yanchor': 'top'})\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By looking over the accuracies graph:\n* 135 is enough for k-value.\n* Manhattan distance performs better when k has low value. If k value is higher than usual euclidean is the better option.\n* Uniform weights are better.","metadata":{}},{"cell_type":"code","source":"knn_model = KNeighborsClassifier(n_neighbors=135)\nknn_model.fit(X_train, y_train)\ny_pred = knn_model.predict(X_validation)\nplt.title(\"KNN Confusion Matrix for Validation Data\", fontdict={'fontsize':18})\nax = sns.heatmap(confusion_matrix(y_validation, y_pred), annot=True, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. SVM (Support-Vector Machine)","metadata":{}},{"cell_type":"code","source":"svm_model = SVC()\nsvm_model.fit(X_train, y_train)\nprint(\"Accuracy for SVM on validation data: {}%\".format(round((svm_model.score(X_validation, y_validation)*100),2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = svm_model.predict(X_validation)\nplt.title(\"SVM Confusion Matrix for Validation Data\", fontdict={'fontsize':18})\nax = sns.heatmap(confusion_matrix(y_validation, y_pred), annot=True, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our Machine Learning models doing well with validation data.","metadata":{}},{"cell_type":"markdown","source":"# 4. Classification with Neural Networks\nFirsty, I would like to try different models like with or without regularization methods. I will create four different models:\n1. Without regularization\n2. With 0.2 dropout regularization\n3. With L1(Lasso) regularization\n4. With L2(Ridge) regularization\n\nAfter all models trained and evaluated with validation data, we will compare the training and validation losses.","metadata":{}},{"cell_type":"code","source":"# NN without regularization\nmodel1 = Sequential()\nmodel1.add(Dense(32, activation='relu', input_dim=6))\nmodel1.add(Dense(16, activation='relu'))\nmodel1.add(Dense(1, activation='sigmoid'))\nmodel1.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhistory1 = model1.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_validation, y_validation))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NN with 0.2 dropout ratio before the hidden layer.\nmodel2 = Sequential()\nmodel2.add(Dense(32, activation='relu', input_dim=6))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(16, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))\nmodel2.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhistory2 = model2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_validation, y_validation))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NN with L1(Lasso) regularization\nmodel3 = Sequential()\nmodel3.add(Dense(32, activation='relu', input_dim=6, kernel_regularizer=l1(l=0.01)))\nmodel3.add(Dense(16, activation='relu', kernel_regularizer=l1(l=0.01)))\nmodel3.add(Dense(1, activation='sigmoid'))\nmodel3.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhistory3 = model3.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_validation, y_validation))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NN with L2(Ridge) Regularization\nmodel4 = Sequential()\nmodel4.add(Dense(32, activation='relu', input_dim=6, kernel_regularizer=l2(l=0.01)))\nmodel4.add(Dense(16, activation='relu', kernel_regularizer=l2(l=0.01)))\nmodel4.add(Dense(1, activation='sigmoid'))\nmodel4.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhistory4 = model4.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_validation, y_validation))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss1 = history1.history['loss']\nval_loss1 = history1.history['val_loss']\nloss2 = history2.history['loss']\nval_loss2 = history2.history['val_loss']\nloss3 = history3.history['loss']\nval_loss3 = history3.history['val_loss']\nloss4 = history4.history['loss']\nval_loss4 = history4.history['val_loss']\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.arange(len(loss1)), y=loss1,\n                    name='Training Loss without Regularization', line=dict(color='royalblue')))\nfig.add_trace(go.Scatter(x=np.arange(len(val_loss1)), y=val_loss1,\n                    name='Validation Loss without Regularization', line = dict(color='firebrick')))\n\nfig.add_trace(go.Scatter(x=np.arange(len(loss2)), y=loss2,\n                    name='Training Loss with Dropout', line=dict(color='royalblue', dash='dash')))\nfig.add_trace(go.Scatter(x=np.arange(len(val_loss2)), y=val_loss2,\n                    name='Validation Loss with Dropout', line = dict(color='firebrick', dash='dash')))\n\nfig.add_trace(go.Scatter(x=np.arange(len(loss3)), y=loss3,\n                    name='Training Loss with L1 Regularization', line=dict(color='royalblue', dash='dot')))\nfig.add_trace(go.Scatter(x=np.arange(len(val_loss3)), y=val_loss3,\n                    name='Validation Loss with L1 Regularization', line = dict(color='firebrick', dash='dot')))\n\nfig.add_trace(go.Scatter(x=np.arange(len(loss4)), y=loss4,\n                    name='Training Loss with L2 Regularization', line=dict(color='royalblue', dash='longdashdot')))\nfig.add_trace(go.Scatter(x=np.arange(len(val_loss4)), y=val_loss4,\n                    name='Validation Loss with L2 Regularization', line = dict(color='firebrick', dash='longdashdot')))\n\n\nfig.update_layout(xaxis_title='Epochs',\n                  yaxis_title='Loss',\n                  title={'text': \"Training and Validation Losses for Different Models\",\n                                                'x':0.5,\n                                                'xanchor': 'center',\n                                                'yanchor': 'top'})\niplot(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* NN without regularization is unstabilized as expected.\n* Dropout and L2 regularization doing well.\n* L1 regularization is stable but it has biggest loss value.\n\nSo our best option will be a dropout layer and L2 regularization on layers. Let's train it.\n\nP.S. You can click on the legend to close some of lines. It might be useful when examining the plot.","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=6, kernel_regularizer=l2(l=0.01)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(32, activation='relu', kernel_regularizer=l2(l=0.01)))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop',\n                loss='binary_crossentropy',\n                metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Comparing Performances of SVM and Neural Network\nLet's test our models with the test data. This data has nearly 10000 instances. I will evaluate them with accuracy metric first, after then we will look into confusion matrix.","metadata":{}},{"cell_type":"code","source":"print(\"Accuracy for SVM on test data: {}%\\n\".format(round((svm_model.score(X_test, y_test)*100),2)))\nprint(\"Accuracy for Neural Network model on test data: {}%\".format(round((model.evaluate(X_test, y_test)[1]*100),2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems very close right?","metadata":{}},{"cell_type":"code","source":"y_pred = svm_model.predict(X_test)\nplt.title(\"SVM Confusion Matrix for Test Data\", fontdict={'fontsize':18})\nax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\nthreshold = 0.6\ny_pred = [1 if i >= threshold else 0 for i in y_pred]\nplt.title(\"Neural Network Confusion Matrix for Test Data\", fontdict={'fontsize':18})\nax = sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Conclusion\nBoth of the models did great job when predicting occupancy. Our accuracy is nearly 98%. So what do you think, which method (ML or DL) is suitable for this dataset and problem?\n\nBefore answer that, look at the confusion matrix which are created when evaluating models with the test data. SVM model looks like biased toward occupied class. But we don't have that problem with neural network. So we can say that, we could use neural network for more stable and accurate results without significant errors.","metadata":{}}]}